# ğŸ¬ Netflix ML Pipeline

This repository contains a modular and reproducible machine learning pipeline built with [DVC](https://dvc.org/) and Docker. The goal is to streamline the end-to-end process of data preprocessing, model training, and inference in a clean and organized way.

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ artifacts/            
â”‚   â”œâ”€â”€ valid_movies.pkl
â”‚   â””â”€â”€ valid_users.pkl
â”œâ”€â”€ config/               
â”‚   â”œâ”€â”€ best_params.yaml
â”‚   â”œâ”€â”€ paths.py
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ data/               
â”‚   â”œâ”€â”€ final/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ mlruns/               
â”œâ”€â”€ models/             
â”‚   â””â”€â”€ svd_model.pkl
â”œâ”€â”€ notebooks/               
â”‚   â”œâ”€â”€ eda.ipynb
â”‚   â”œâ”€â”€ model.ipynb
â”‚   â””â”€â”€ predict.ipynb
â”‚   â””â”€â”€ preprocessing.ipynb
â”œâ”€â”€ src/                
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ training.py
â”‚   â””â”€â”€ predictions.py
â”œâ”€â”€ utils/              
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config_loader.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ data_split.py
â”‚   â”œâ”€â”€ files_management.py
â”‚   â””â”€â”€ metrics.py
â”œâ”€â”€ dvc.yaml            
â”œâ”€â”€ Dockerfile          
â”œâ”€â”€ requirements.txt    
â””â”€â”€ environment.yaml    
```

---

## âš™ï¸ Pipeline Stages

The DVC pipeline is defined in `dvc.yaml` and includes the following stages:

1. **Preprocessing** â€“ Cleans and transforms the input data.
2. **Training** â€“ Trains a classification model.
3. **Prediction** â€“ Uses the trained model to generate predictions.

---

## ğŸš€ Getting Started

### 1. Build the Docker Image

```bash
docker build -t netflix-pipeline .
```

> This creates a reproducible environment with Python, DVC, and all necessary dependencies.

### 2. Run the Pipeline

Run the full pipeline from the root of the project directory:

```bash
docker run --rm -v $(pwd):/app netflix-pipeline
```

This command executes `dvc repro` inside the container, automatically running the pipeline stages as needed.

> **Note:** The project must be a Git repository for DVC to work correctly.

---

## ğŸ§ª Run Individual Scripts (Optional)

You can also manually run individual pipeline stages inside the container:

```bash
# Preprocessing
docker run --rm -v $(pwd):/app netflix-pipeline python -m src.preprocessing

# Training
docker run --rm -v $(pwd):/app netflix-pipeline python -m src.training

# Prediction
docker run --rm -v $(pwd):/app netflix-pipeline python -m src.predictions
```

---

## ğŸ“ Volumes & Data Persistence

To preserve data and artifacts between runs, mount the entire project directory using:

```bash
-v $(pwd):/app
```

Alternatively, you can mount folders individually (less recommended):

```bash
docker run --rm \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/artifacts:/app/artifacts \
  netflix-pipeline
```

---

## ğŸ“‹ Requirements

- [Docker](https://www.docker.com/)
- [Git](https://git-scm.com/)
- No need to install Python or DVC locally â€” everything runs inside Docker

---

## âœ… Tips

- Use Git to version control your code and data.
- Use `dvc repro` to re-run the pipeline after modifying code or inputs.
- All stages and file dependencies are tracked in `dvc.yaml`.

---

## ğŸ“„ License

MIT License. See `LICENSE` file for details.
